{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu111\n",
      "4.27.3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import transformers\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from typing import Sequence\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем данные из датасетов\n",
    "ratings_df  = pd.read_csv('../input/ratings.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head() # Смотрю что в них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     1,      2,      3, ..., 283226, 283227, 283228], dtype=int64),\n",
       " array([   307,    481,   1091, ..., 117857, 133409, 142855], dtype=int64),\n",
       " 283228,\n",
       " 53889)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = ratings_df[\"userId\"].unique() # Создаю массив с уникальными юзерами\n",
    "item_ids = ratings_df['movieId'].unique() # Также с фильмами\n",
    "user_ids, item_ids, ratings_df[\"userId\"].nunique(), ratings_df['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uid2idx = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "#iid2idx = {iid: idx for idx, iid in enumerate(item_ids)}\n",
    "#idx2uid = {idx: uid for uid, idx in uid2idx.items()}\n",
    "#idx2iid = {idx: iid for iid, idx in iid2idx.items()}\n",
    "#ratings_df['userId'] = ratings_df['userId'].map(uid2idx)\n",
    "#ratings_df['movieId'] = ratings_df['movieId'].map(iid2idx)\n",
    "#ratings_df\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42) # сплитим данные\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172143</td>\n",
       "      <td>3740</td>\n",
       "      <td>2.0</td>\n",
       "      <td>992045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2440</td>\n",
       "      <td>1185</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1356461438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38145</td>\n",
       "      <td>3275</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1471179958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83252</td>\n",
       "      <td>223</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1008482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159137</td>\n",
       "      <td>4389</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1065371794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22202750</th>\n",
       "      <td>215366</td>\n",
       "      <td>115122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1507121815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22202751</th>\n",
       "      <td>274263</td>\n",
       "      <td>4262</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1400987773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22202752</th>\n",
       "      <td>238530</td>\n",
       "      <td>590</td>\n",
       "      <td>3.0</td>\n",
       "      <td>834347371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22202753</th>\n",
       "      <td>164462</td>\n",
       "      <td>4643</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1238069592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22202754</th>\n",
       "      <td>237215</td>\n",
       "      <td>1172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>857805479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22202755 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp\n",
       "0         172143     3740     2.0   992045228\n",
       "1           2440     1185     3.5  1356461438\n",
       "2          38145     3275     0.5  1471179958\n",
       "3          83252      223     5.0  1008482300\n",
       "4         159137     4389     3.5  1065371794\n",
       "...          ...      ...     ...         ...\n",
       "22202750  215366   115122     4.5  1507121815\n",
       "22202751  274263     4262     4.0  1400987773\n",
       "22202752  238530      590     3.0   834347371\n",
       "22202753  164462     4643     3.5  1238069592\n",
       "22202754  237215     1172     3.0   857805479\n",
       "\n",
       "[22202755 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  283228\n",
      "Number of movies:  53889\n",
      "Number of interactions:  27753444\n",
      "Average rating:  3.5304452124932677\n",
      "Start Date:  1995-01-09 11:46:44\n",
      "End Date:  2018-09-26 06:59:09\n"
     ]
    }
   ],
   "source": [
    "print('Number of users: ', len(user_ids))\n",
    "print('Number of movies: ', len(item_ids))\n",
    "print('Number of interactions: ', len(ratings_df))\n",
    "print('Average rating: ', ratings_df['rating'].mean())\n",
    "print('Start Date: ', pd.to_datetime(ratings_df['timestamp'].min(), unit='s'))\n",
    "print('End Date: ', pd.to_datetime(ratings_df['timestamp'].max(), unit='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensTrainDataset(Dataset):\n",
    "    \"\"\"MovieLens PyTorch Dataset for Training\n",
    "    \n",
    "    Args:\n",
    "        ratings (pd.DataFrame): Dataframe containing the movie ratings\n",
    "        all_movieIds (list): List containing all movieIds\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratings, all_movieIds):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_movieIds):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n",
    "\n",
    "        num_negatives = 4\n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_movieIds)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS\n",
    "\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF)\n",
    "    \n",
    "        Args:\n",
    "            num_users (int): Number of unique users\n",
    "            num_items (int): Number of unique items\n",
    "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
    "            all_movieIds (list): List containing all movieIds (train + test)\n",
    "    \"\"\"\n",
    "    loss_val = list()\n",
    "    val_losses = list()\n",
    "    loss_train = list()\n",
    "    train_losses = list()\n",
    "    \n",
    "    split_seed = 12345\n",
    "    k = 1\n",
    "    \n",
    "    data_train = []\n",
    "    data_val = []\n",
    "    def __init__(self, num_users, num_items, ratings, all_movieIds, num_splits = 5, k = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Определяем слои для входных эмбеддингов пользователей и фильмов\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "\n",
    "        # Определяем полносвязные слои и выходной слой сигмоидной активации\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "        # Сохраняем оценки фильмов и список всех фильмов\n",
    "        self.num_splits = num_splits\n",
    "        self.ratings = ratings\n",
    "        self.all_movieIds = all_movieIds\n",
    "        self.k = k\n",
    "\n",
    "        self.loss_val = []\n",
    "        self.val_losses = []\n",
    "        self.loss_train = []\n",
    "        self.train_losses = []\n",
    "\n",
    "        assert 1 <= self.k <= self.num_splits, \"incorrect fold number\"\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        # Передаем входные данные через слои эмбеддингов\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        # Объединяем эмбеддинги\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        # Проходим через полносвязные слои\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        # Выходной слой\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        # Бинарная перекрестная энтропия как функция потери\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        self.loss_train.append(loss.item())\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        self.loss_val.append(loss.item())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        #if not self.data_train and not self.data_val:\n",
    "        dataset_full = self.ratings\n",
    "\n",
    "        # choose fold to train on\n",
    "        kf = KFold(n_splits=self.num_splits, shuffle=True, random_state=self.split_seed)\n",
    "        all_splits = [k for k in kf.split(dataset_full)]\n",
    " \n",
    "        train_indexes, val_indexes = all_splits[self.k]\n",
    "        train_indexes, val_indexes = train_indexes.tolist(), val_indexes.tolist()\n",
    "        self.data_train, self.data_val = dataset_full.loc[train_indexes], dataset_full.loc[val_indexes]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensTrainDataset(self.data_train, self.all_movieIds),\n",
    "                          batch_size=512)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(MovieLensTrainDataset(self.data_val, self.all_movieIds),\n",
    "                          batch_size=512) # можно добавить num_workers - у меня работало в колабе, но на своем устройстве ошибка c PID \n",
    "                                          # https://stackoverflow.com/questions/60101168/pytorch-runtimeerror-dataloader-worker-pids-15332-exited-unexpectedly\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        avg_loss = np.average(self.loss_train)\n",
    "        self.loss_train.clear()\n",
    "        self.train_losses.append(avg_loss)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = np.average(self.loss_val)\n",
    "        self.loss_val.clear()\n",
    "        self.val_losses.append(avg_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings_df['userId'].max()+1\n",
    "num_items = ratings_df['movieId'].max()+1\n",
    "\n",
    "all_movieIds = ratings_df['movieId'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(raitings_df, test_data, model):\n",
    "    ratings_df_copy = ratings_df.copy()\n",
    "    test_data_copy = test_data.copy()\n",
    "\n",
    "    # Перемешаю и дропну некоторые тестовые данные для экономии времени (можно сделать на всех если есть время)\n",
    "    test_data_copy.sample(frac=1)\n",
    "    test_data_copy.drop(test_data_copy.index[int(len(test_data_copy)/100):len(test_data_copy)-1], axis=0, inplace=True) \n",
    "\n",
    "    # Создаем множество пользователей и фильмов из тестовых данных\n",
    "    test_user_item_set = set(zip(test_data_copy['userId'], test_data_copy['movieId']))\n",
    "\n",
    "    # Группируем идентификаторы фильмов для каждого пользователя в словаре\n",
    "    user_interacted_items = ratings_df_copy.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "    # Создаем список для хранения результатов оценки качества предсказаний\n",
    "    hits = []\n",
    "\n",
    "    # Для каждой пары (пользователь, фильм) в тестовых данных\n",
    "    for (u,i) in tqdm(test_user_item_set):\n",
    "\n",
    "        # Получаем список идентификаторов фильмов, с которыми взаимодействовал данный пользователь\n",
    "        interacted_items = user_interacted_items[u]\n",
    "\n",
    "        # Создаем множество идентификаторов фильмов, с которыми пользователь не взаимодействовал\n",
    "        not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
    "\n",
    "        # Случайным образом выбираем 99 не взаимодействовавших фильмов и добавляем целевой фильм\n",
    "        selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "        test_items = selected_not_interacted + [i]\n",
    "\n",
    "        # Получаем предсказанные оценки для каждого из выбранных фильмов\n",
    "        predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
    "                                            torch.tensor(test_items)).detach().numpy())\n",
    "        # Получаем идентификаторы 10 фильмов с наивысшими предсказанными оценками\n",
    "        top10_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "\n",
    "        # Проверяем, содержится ли целевой фильм в топ-10 предсказанных\n",
    "        if i in top10_items:\n",
    "            hits.append(1)\n",
    "        else:\n",
    "            hits.append(0)\n",
    "    # Выводим значение метрики Hit Ratio @ 10        \n",
    "    print(\"The Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))\n",
    "    return np.average(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 2.3 M \n",
      "1 | item_embedding | Embedding | 1.6 M \n",
      "2 | fc1            | Linear    | 1.1 K \n",
      "3 | fc2            | Linear    | 2.1 K \n",
      "4 | output         | Linear    | 33    \n",
      "---------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.281    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f18dceca79647b9aa0be29553e529e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "nums_folds = 5\n",
    "for k in range(nums_folds):\n",
    "    trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=1, reload_dataloaders_every_n_epochs=0,\n",
    "                     enable_progress_bar=True, logger=False, enable_checkpointing=False)\n",
    "    model = NCF(num_users, num_items, train_data, all_movieIds, num_splits=nums_folds+1, k = k+1)\n",
    "    model.setup()\n",
    "    trainer.fit(model)\n",
    "    \n",
    "    torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    }, 'models/cross_val/with_val_3_epoches_'+str(k)+'.pth')\n",
    "\n",
    "    results.append(metric(train_data, test_data, model))\n",
    "    model.zero_grad()\n",
    "    model.user_embedding.reset_parameters()\n",
    "    model.item_embedding.reset_parameters()\n",
    "    model.fc1.reset_parameters()\n",
    "    model.fc2.reset_parameters()\n",
    "    model.output.reset_parameters()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(1, 2, 1)\n",
    "#plt.plot(model.train_losses)\n",
    "#plt.plot(model.val_losses)\n",
    "#plt.legend(['train','val'])\n",
    "#plt.title('Training loss')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
